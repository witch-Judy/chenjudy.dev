---
author: Chen Judy
pubDatetime: 2026-02-27T12:00:00.000Z
title: "多Agent系统设计的五条第一性原理"
category: notes
tags:
  - AI
  - Agent
  - 系统设计
description: "基于 Google Research 论文 Towards a Science of Scaling Agent Systems 的核心发现，提炼出评判任何 Agent 系统的五条通用原理。"
---

> 基于 Google Research 论文 *"Towards a Science of Scaling Agent Systems"* 的核心发现提炼而成。这五条原理独立于具体的模型和数据，构成评判任何Agent系统的通用透镜。

---

## 前置知识：五种Agent架构

在理解第一性原理之前，需要先了解论文评估的五种典型Agent架构。它们覆盖了从最简单到最复杂的协作模式，几乎所有现实中的Agent系统都可以归类为其中之一或其变体。

### SAS（单Agent系统）

一个Agent独自完成所有工作。所有的感知、推理、行动都在一个顺序循环中进行，由单一的LLM实例控制，维护一条统一的记忆流。即使使用了工具调用、自我反思或链式思维，只要只有一个决策主体，就仍然是SAS。它的优势是零通信开销、完整的上下文保持；劣势是无法并行、缺乏外部验证。

### MAS - 独立式（Independent）

多个Agent并行处理子任务，彼此之间没有通信，最终结果通过简单聚合（如多数投票）或由外部逻辑合并。每个Agent看到相同的输入，独立产生输出。优势是最高的并行度和零通信开销；劣势是Agent之间无法互相纠错、无法处理需要协作的任务。

### MAS - 去中心化（Decentralized）

所有Agent地位平等，通过全连接的点对点通信进行协作。没有"老板"，每个Agent既是Worker也是Reviewer。优势是任何错误都有多个同伴可以检测；劣势是通信开销随Agent数量呈二次增长，且容易形成群体极化或信息循环。

### MAS - 集中式（Centralized）

一个协调者Agent负责分配任务、整合结果，Worker Agent执行具体子任务并只与协调者通信（星形拓扑）。优势是通信开销可控、有明确的质量把关点；劣势是协调者成为瓶颈和单点故障，且协调本身消耗token预算。

### MAS - 混合式（Hybrid）

在集中式的基础上，Worker之间也可以进行有限的直接通信。协调者负责全局调度，但Worker可以在需要时直接交换信息。理论上兼具层级控制的有序性和横向沟通的灵活性；实践中额外的通信渠道会消耗更多token预算，且可能引入信息冲突，论文实验显示它在多数场景下并不优于纯集中式。

### 架构复杂度一览

| 架构 | 通信方式 | 通信开销 | 并行度 | 验证机制 |
|------|----------|----------|--------|----------|
| SAS | 无 | 零 | 无 | 自我检查 |
| 独立式 | 无（仅最终汇聚） | 极低 | 最高 | 无 |
| 去中心化 | 全连接点对点 | 高 | 高 | 同伴互查 |
| 集中式 | 星形（经协调者） | 中 | 高 | 协调者验证 |
| 混合式 | 星形 + 部分点对点 | 最高 | 高 | 协调者 + 同伴 |

**关键洞察：** 架构复杂度的增加并不等于性能的提升。论文最重要的发现之一是，更简洁的架构（SAS或集中式）在大多数场景下优于更复杂的架构（混合式或深层级），因为复杂通信消耗的认知预算往往超过其带来的信息增益。

---

## 原理一：认知预算守恒

**一句话：Agent之间的每一次通信都直接消耗原本可用于解题的认知预算——通信不是免费的附加功能，而是从固定预算中扣除的刚性成本。**

在固定token预算下（这是现实世界的硬约束），Agent之间传递的每一条消息都占用了原本可以用来思考、推理、解决问题的token。这不是一个可以通过优化来消除的开销——它是多Agent架构的内在物理定律。

论文数据显示：集中式架构中，协调者与Worker之间的通信平均消耗总token预算的15-25%。混合式架构中，这个比例更高。这意味着，一个3-Agent集中式系统中，每个Worker实际可用于解题的认知预算只有单Agent系统的25-28%（总预算的75%除以3个Worker）。

**直觉类比：**
想象一个公司有8小时工作日。一个人干活就是8小时实打实。三个人的小组看似有24人时，但开会协调需要时间。如果是扁平的小组（集中式），可能需要2小时开会，剩下22人时干活。如果是三层管理结构（组长→员工，层层汇报）可能光内部流转就耗掉4小时。会议（通信）不是免费的，它直接从做事（推理）的时间里扣除。

**评判标准：**
拿到一个Agent系统时问两个问题——Agent之间的通信占了总token消耗的多少？这些通信产生了多少**不可替代的**信息增益？如果一个系统的通信税率很高，但换来的只是重复确认已知信息，那就是在浪费认知预算。

---

## 原理二：错误的拓扑放大

**一句话：系统的可靠性不取决于单个Agent有多强，而取决于错误在传播路径上是否存在检查点。**

一个Agent犯的错误能影响多少个其他Agent、能不能被纠正、会不会被放大，完全取决于系统的通信拓扑结构。

三种典型模式形成鲜明对比：没有通信的独立式看似"隔离了风险"，但错误无人纠正，在最终汇总时反而被放大了17.2倍。全连接的去中心化让错误有机会被同伴发现，但也让错误可以通过社交影响链条扩散。集中式通过协调者作为检查点，在错误传播和纠正之间取得了最佳平衡。

**直觉类比：**
独立式像是让三个学生独立做同一道数学题然后取多数答案——如果题目简单还行，但如果题目难到两个人都错了，多数投票反而选了错误答案。去中心化像是让三个学生讨论着做——错误可能被发现也可能被"带偏"（一个自信的错误学生说服了犹豫的正确学生）。集中式像是有一个老师监督，学生做完后老师检查——老师本身也可能犯错，但至少提供了一个独立的检查点。

**评判标准：**
画出系统中错误的传播路径图。问自己：一个Agent在第一步犯了错误，这个错误最远能传播到哪里？传播路径上有几个独立的检查点？如果答案是"可以不经任何检查直达最终输出"，这个系统的架构就有严重的可靠性风险。

---

## 原理三：架构-任务对齐决定性能天花板

**一句话：同样的Agent团队，放在匹配的架构上和放在错误的架构上，性能差距可以高达数倍——这个差距比换模型、调参数带来的改进大一个数量级。**

论文最令人震惊的发现是：在同一个任务上，同一个基础模型、同样数量的Agent，仅仅改变架构（从SAS到集中式，或从独立式到去中心化），性能可以从0.18跃升到0.58，也可以从0.60暴跌到0.18。唯一的区别是任务结构与架构的匹配程度。

这意味着：系统的性能天花板首先由架构与任务的对齐度决定，其次才由Agent数量和模型能力决定。在错误的架构上堆更多Agent或换更强的模型，就像在错误的赛道上换更快的轮胎——收益递减甚至为负。在正确的架构上，即使用较弱的模型也能获得不错的结果。

**直觉公式：**

```
实际性能 = f(架构-任务匹配度) × g(Agent数量, 模型能力)
```

第一项是乘法关系中的主导项。如果匹配度为零（比如在严格顺序任务上用独立并行架构），不管第二项多大，乘出来都很差。

**例子：**
搬一架钢琴上楼和搬100箱书上楼，需要完全不同的组织方式。搬书可以10个人并行，每人搬10箱；搬钢琴必须4个人同步配合，步调一致。如果你按"搬书模式"来组织搬钢琴（每人搬钢琴的一个角？），不是效率低的问题，是根本完不成。架构错了，人再多也没用。

**评判标准：**
在选择架构之前先分析任务结构：这个任务的子步骤之间有多强的依赖关系？能不能真正并行？需要多少共享上下文？答案直接指向最优架构类型。

---

## 原理四：能力饱和天花板

**一句话：多Agent系统的增益随基础模型能力的提升而递减——模型越强，多Agent的边际价值越低，直至为负。**

当基础模型足够强大时，单Agent已经能很好地完成任务，多Agent带来的增量改进不足以覆盖协调成本。论文数据显示，在某些任务上，强模型的SAS表现优于弱模型的最优多Agent配置。这意味着随着基础模型的持续进化，很多今天需要多Agent的任务明天可能单Agent就够了。以"多Agent架构"作为核心壁垒的产品，其壁垒会被基础模型的进步自然侵蚀。

**例子：**
考试辅导的类比。一个学生数学只能考30分，请三个家教从不同角度辅导，可能效果显著。但如果学生已经能考85分了，三个家教之间的意见分歧、排课冲突、教学风格矛盾反而会让学生困惑，不如一个好家教持续深耕。"多Agent"就像多个家教——学生越弱它们越有用，学生越强它们越容易帮倒忙。

**评判标准：**
这个多Agent系统解决的问题，先拿一个单Agent跑一下基线。如果单Agent已经做到了相当不错的水平，那就要严肃地问：多Agent带来的增量，真的值那个协调成本吗？还是单Agent加上更好的prompt工程就能达到同样效果？

---

## 原理五：信息探索与任务执行的二象性

**一句话：任务的核心瓶颈是"找到答案"还是"执行答案"，决定了最优的Agent拓扑。**

任务可以分布在一个光谱上：一端是"信息探索密集型"（不确定答案在哪里，需要广泛搜索），另一端是"执行密集型"（知道该做什么，但执行步骤复杂且有严格顺序）。

探索型任务天然适合多Agent并行搜索——多个Agent同时探索不同方向，汇总发现。执行型任务天然适合单Agent顺序执行——因为每一步都依赖前一步的结果，并行化反而引入同步开销。

**评判标准：**
系统面对的核心挑战是"不知道答案在哪"（探索），还是"知道该做什么但执行很复杂"（执行）？如果是前者，去中心化的广泛探索可能更优；如果是后者，集中式的有序调度更优。系统的拓扑结构是否与任务的信息不确定性匹配？

---

## 如何使用这五条原理

这五条原理构成一个快速评估清单。面对任何Agent系统，依次回答五个问题：

| 原理 | 核心问题 | 红旗信号 |
|------|----------|----------|
| 认知预算守恒 | 通信税率合理吗？ | 超过30%的token花在Agent间通信上，但无法说明信息增益 |
| 错误拓扑放大 | 错误传播路径上有检查点吗？ | 错误可以不经任何验证直达最终输出 |
| 架构-任务对齐 | 架构选择有任务结构分析支撑吗？ | "因为多Agent更先进所以用多Agent" |
| 能力饱和天花板 | 单Agent是不是已经够用？ | 单Agent基线已经不错，但仍堆了多Agent |
| 探索-执行二象性 | 拓扑与信息不确定性匹配吗？ | 执行型任务用了探索型拓扑，或反之 |

如果五个问题中有三个以上亮红旗，这个系统大概率需要架构层面的重新设计，而不是参数层面的优化。

---

## 推论与实践方法论

### 推论A：工具密集型任务倾向于SAS

**当一个Agent需要使用大量工具（16+个）时，多Agent的协调税很可能超过并行收益，优先考虑SAS。**

**例子：** 一个软件工程任务需要Agent使用读文件、写文件、运行代码、执行测试、搜索代码库、查看git日志、安装依赖、调用linter等16+个工具。如果把这个任务交给3个Agent分头做，每个Agent都需要学会使用全部工具（或者一个子集，但需要额外协调谁用哪个工具），光工具相关的token消耗就被三倍化了，而实际推理的budget被严重挤压。不如一个熟练的Agent从头到尾自己操作。

### 推论B：时刻计算成本，token消耗是恒定的

**多Agent系统的成本分析应该是架构决策的前置步骤，而不是事后的优化。**

论文的所有实验都在**固定token预算**的约束下进行。这个设定不是实验的简化假设，而是反映了真实世界的硬约束——无论你用什么架构，底层的LLM API调用是按token计费的，预算总是有限的。

这意味着：多Agent系统不是"花更多钱就能更好"，而是"在同样的钱下，如何分配给推理vs通信"的零和博弈。选了3-Agent集中式，每次调用的token量就大致固定了——这不是后期能通过"优化"大幅削减的变量，而是架构选择的直接后果。

### 推论C：多层级Agent架构的幻觉

**论文中所有多Agent架构都是扁平的（一层协调者+Worker），没有任何实验支持"层级越深越好"的论点。**

然而在实际的AI产品中，我们经常看到三层、四层甚至更深的Agent层级结构。这种设计直觉来源于人类组织管理的类比——"大公司有CEO、VP、Director、Manager，所以AI系统也应该有类似的层级"。

这个类比的根本缺陷是：人类组织的层级存在是因为**人类个体的认知带宽有限**（一个人最多管理7±2个直接下属），而LLM的context window可以同时处理数千到数十万token的信息。人类需要层级来压缩和传递信息，LLM不需要。

用论文的五条第一性原理逐一审视：

**违反原理一：** 认知预算被层级吞噬。每一层汇总都消耗token，且是有损压缩——细节被丢弃、语义被扭曲。在固定token预算下，一个两层架构可能有40%的token花在通信上，三层可能超过60%。

**违反原理二：** 错误传播链过长。每多一个层级，错误在到达顶层决策者之前就多经过一个可能引入偏差的环节。论文发现Agent之间10次交互后世界状态的重叠度只剩34%。

**违反原理四：** 如果基础模型足够强，一个Agent加上足够的context就能做协调者+Worker的工作，根本不需要层级。

那为什么还有这么多多层级Agent产品？部分原因是**叙事驱动的架构设计**。"我们有CEO Agent、CTO Agent、Product Manager Agent"，这种叙事对投资人和媒体很有吸引力。但工程上的最优解和叙事上的吸引力往往是两码事。

**判断标准很简单：** 如果一个AI产品宣传自己用了"类大厂管理架构的多层级Agent系统"，基于这篇论文的研究，正确的第一反应应该是怀疑，而不是佩服。

---

## 实践方法论：从直觉到验证

### 公式的冷启动问题

论文提出的预测模型（R²=0.513，87%架构预测准确率）在学术上很有价值，但在实践中有一个"鸡生蛋"的问题：模型的输入变量——协调效率、错误放大率、冗余度——都是需要**先跑一遍Agent系统才能测出来的经验指标**。你想用模型来决定选哪种架构，但需要先把各种架构都跑一遍才能得到输入。

这意味着直觉规则在实践中可能反而更实用——它们虽然粗糙，但不需要先跑实验就能用。

### 推荐的三步决策流程

**第一步：任务分析（5分钟）**
- 这个任务能拆成独立子任务吗？→ 能：考虑多Agent并行
- 子任务之间有严格的顺序依赖吗？→ 有：倾向SAS
- 核心瓶颈是探索还是执行？→ 探索：多Agent；执行：SAS
- 需要多少工具？→ 16+：强烈倾向SAS

**第二步：SAS基线（1小时）**
- 永远先跑一个SAS基线。这是你的参照点
- 如果SAS已经达到80%+的满意度，认真考虑是否真的需要多Agent

**第三步：最小多Agent验证（半天）**
- 如果SAS不够，选择**最简单的**多Agent架构（通常是集中式2-3 Agent）
- 对比SAS基线，计算：性能提升了多少？成本增加了多少？
- 如果性能提升 < 成本增加，选择SAS

### 核心心态：成本意识贯穿始终

整个决策流程中，有一条隐含的假设需要时刻铭记：**token消耗在架构确定后基本是恒定的。** 你选了集中式3-Agent架构，每次任务调用的token量就大致固定了。这不是一个你能在后期通过"优化"大幅削减的变量——它是架构选择的直接后果。

因此，成本分析必须是**前置步骤**，而不是"先跑起来再说"。在第一步选架构时就应该粗算：这种架构大概比SAS多消耗多少token？我的预算能承受吗？在规模化部署后这个成本可持续吗？

很多团队的错误是先选了一个复杂的多Agent架构，开发了几个月，上线后才发现token成本是预期的10倍，然后再回头简化架构——这个过程中浪费的时间和工程成本远远超过一开始花10分钟做成本估算。

---

*原始论文：Yubin Kim, Xin Liu et al., "Towards a Science of Scaling Agent Systems: When and Why Agent Systems Work", Google Research, 2025.*
